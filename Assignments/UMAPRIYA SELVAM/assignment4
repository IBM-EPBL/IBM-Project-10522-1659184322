# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sPA0xYSGHrowks-qmJgptIpWBOQeHG0l

Import required library
"""

import pandas as pd
import numpy as np
from keras.layers import * 
from keras.models import Model
from keras.optimizers import RMSprop
from keras.preprocessing import sequence
from keras.utils import pad_sequences
from keras.preprocessing.text import Tokenizer
import warnings
warnings.filterwarnings("ignore")
from sklearn.model_selection import train_test_split 
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score\

from google.colab import drive
drive.mount('/content/drive')

df=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/spam.csv", encoding="ISO-8859-1")

max_len=200
max_words = 1000

df.head()

"""Data preprocessing"""

#Replacing null values
md=df.where((pd.notnull(df)),'')

md.head()

md.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)
md.info()

md.head()

#checking number of rows and columns
md.shape

"""Label encoding"""

#Label spam=0,ham=1
md.loc[md['v1']=='spam','v1',]=0
md.loc[md['v1']=='ham','v1',]=1

"""Seperating text and label"""

md.head

x=md['v2']
y=md['v1']

print(x)

print(y)

inputs = Input(name='inputs',shape=[max_len])
layer = Embedding(max_words,50,input_length=max_len)(inputs)
layer = LSTM(64)(layer)
layer = Dense(256,name='FC1')(layer)
layer = Activation('relu')(layer)
layer = Dropout(0.5)(layer)
layer = Dense(1,name='out_layer')(layer)
layer = Activation('sigmoid')(layer)
model = Model(inputs=inputs,outputs=layer)
model.summary()

"""Splitting data into training and testing set"""

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=3)

print(x.shape)
print(x_test.shape)
print(x_train.shape)

"""Feature extraction"""

#Transform text data into feature vectors 
fe=TfidfVectorizer(min_df=1,stop_words='english',lowercase='true')

x_train_features=fe.fit_transform(x_train)
x_test_features=fe.transform(x_test)

y_train=y_train.astype('int')
y_test=y_test.astype('int')

print(x_train_features)

"""Training the model"""

tok = Tokenizer(num_words=max_words)
tok.fit_on_texts(x_train)
sequences = tok.texts_to_sequences(x_train)
sequences_matrix = pad_sequences(sequences,maxlen=max_len)

model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])

model.fit(sequences_matrix,y_train,batch_size=128,epochs=10,validation_split=0.2)

"""Preprocessing the Test Dataset

"""

test_sequences = tok.texts_to_sequences(x_test)
test_sequences_matrix = pad_sequences(test_sequences,maxlen=max_len)

accr = model.evaluate(test_sequences_matrix,y_test)

